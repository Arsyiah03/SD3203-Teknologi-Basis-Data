# Nama : Arsyiah azahra
# kelas : TBD RC
# NIM : 121450035

# Tiga Cara Menyimpan dan Mengakses Banyak Gambar di Python


## Pendahuluan
Dalam tugas ini saya akan me re-implementasikan berbagai metode untuk menyimpan dan mengakses banyak gambar dalam bahasa pemrogaraman Pyhton. Ketika kita memiliki sedikit gambar, cara standar seperti menyimpannya sebagai file .png atau .jpg sudah cukup baik. Namun, ketika jumlah gambar meningkat, seperti dalam penggunaan algoritma pembelajaran mesin seperti convnets, cara penyimpanan standar bisa menjadi kurang efisien.

Pada Tugas ini saya akan menjelaskan alternatif seperti menyimpan gambar dalam basis data yang memungkinkan akses cepat, atau dalam format data hirarkis untuk efisiensi yang lebih baik. Hal ini penting ketika Anda bekerja dengan kumpulan data besar, seperti ImageNet, yang memiliki jutaan gambar.

Disini kita akan mempeajari tiga fungsi yaitu Menyimpan ke Disk, Menyimpan ke lmdb (Internet Movie Database), dan Menyimpan ke hdf5 (H5 adalah salah satu Format Data Hierarkis).

let's read the explanation below

## Setup
Kita akan menggunakan dataset gambar Canadian Institute for Advanced Research, yang lebih dikenal sebagai CIFAR-10, yang terdiri dari 60.000 gambar berwarna 32x32 piksel yang termasuk dalam kelas objek yang berbeda, seperti anjing, kucing, dan pesawat terbang. Secara relatif, CIFAR bukanlah dataset yang sangat besar, tetapi jika kita ingin menggunakan dataset TinyImages secara penuh, maka Anda akan membutuhkan sekitar 400GB ruang disk kosong, yang mungkin akan menjadi faktor pembatas. Nah, selanjutnya kita dapat menginstall paket Python yang akan digunakan untuk menjalankan ketiga metode tersebut.



```python
import numpy as np
import pickle
from pathlib import Path

# Path to the unzipped CIFAR data
data_dir = Path("/content/cifar-10-batches-py")

# Unpickle function provided by the CIFAR hosts
def unpickle(file):
    with open(file, "rb") as fo:
        dict = pickle.load(fo, encoding="bytes")
    return dict

images, labels = [], []
for batch in data_dir.glob("data_batch_*"):
    batch_data = unpickle(batch)
    for i, flat_im in enumerate(batch_data[b"data"]):
        im_channels = []
        # Each image is flattened, with channels in order of R, G, B
        for j in range(3):
            im_channels.append(
                flat_im[j * 1024 : (j + 1) * 1024].reshape((32, 32))
            )
        # Reconstruct the original image
        images.append(np.dstack((im_channels)))
        # Save the label
        labels.append(batch_data[b"labels"][i])

print("Loaded CIFAR-10 training set:")
print(f" - np.shape(images)     {np.shape(images)}")
print(f" - np.shape(labels)     {np.shape(labels)}")
```

    Loaded CIFAR-10 training set:
     - np.shape(images)     (50000, 32, 32, 3)
     - np.shape(labels)     (50000,)


### Pengaturan untuk Menyimpan Gambar pada Disk
Pertama, kita perlu mengatur environment untuk metode default dalam menyimpan dan mengakses gambar-gambar. Disini kita berasumsi bahwa kita sudah memasang Pyhton versi 3.x di komputer kita dan akan menggunakan library 'Pillow' yang ada di python untuk mengubah-ubah gambar nya:


```python
pip install Pillow
```

    Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)


### Pengaturan untuk Menyimpan Gambar pada lmdb
LMDB, atau yang sering disebut sebagai "Lightning Database," adalah jenis database yang sangat cepat dan menggunakan file yang dipetakan langsung ke dalam memori komputer. Ini berbeda dari database relasional yang biasanya digunakan.
Salah satu keunggulan utama LMDB adalah karena data disimpan langsung di dalam memori, sehingga tidak perlu menyalin data seperti halnya pada beberapa jenis database lainnya. Kemudian kita install library lmbd nya sebagai berikut :


```python
pip install lmdb
```

    Collecting lmdb
      Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)
    [2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m299.2/299.2 kB[0m [31m4.3 MB/s[0m eta [36m0:00:00[0m
    [?25hInstalling collected packages: lmdb
    Successfully installed lmdb-1.4.1


### Pengaturan untuk Menyimpan Gambar pada HDF5
HDF5 adalah format file yang digunakan untuk menyimpan data ilmiah. Ini dikembangkan oleh National Center for Supercomputing Applications dan versi yang paling umum digunakan saat ini adalah HDF5. Format ini terdiri dari dua jenis objek utama: dataset, yang berisi data dalam bentuk array multidimensi, dan grup, yang bisa berisi dataset atau grup lainnya. Dataset harus homogen, artinya mereka harus memiliki tipe dan dimensi yang seragam, meskipun grup dapat menampung objek dengan jenis dan dimensi yang berbeda. Kemudian kita install library HDF5 nya sebagai berikut :


```python
pip install h5py
```

    Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)
    Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.25.2)


# Menyimpan satu Gambar
Sekarang kita akan melihat perbandingan kuantitatif dari tugas-tugas dasar yang kita pedulikan: berapa lama waktu yang dibutuhkan untuk membaca dan menulis file, serta berapa banyak memori disk yang akan digunakan. Ini juga akan menjadi pengantar dasar tentang bagaimana cara kerja metode-metode tersebut, dengan contoh kode tentang bagaimana menggunakannya.
Untuk keperluan eksperimen, kita dapat membandingkan kinerja antara berbagai jumlah file, dengan faktor 10 dari satu gambar hingga 100.000 gambar. Karena lima batch CIFAR-10 kita mencakup 50.000 gambar, kita dapat menggunakan setiap gambar dua kali untuk mencapai 100.000 gambar.
Untuk mempersiapkan eksperimen, kita akan membuat folder untuk setiap metode, yang akan berisi semua file database atau gambar, dan menyimpan jalur ke direktori-direktori tersebut dalam variabel.


```python
from pathlib import Path

disk_dir = Path("data/disk/")
lmdb_dir = Path("data/lmdb/")
hdf5_dir = Path("data/hdf5/")
```

Path tidak secara otomatis membuat folder kecuali Anda secara khusus memintanya:


```python
disk_dir.mkdir(parents=True, exist_ok=True)
lmdb_dir.mkdir(parents=True, exist_ok=True)
hdf5_dir.mkdir(parents=True, exist_ok=True)
```


```python
class CIFAR_Image:
    def __init__(self, image, label):
        self.channels = image.shape[2]
        self.size = image.shape[:2]
        self.image = image.tobytes()
        self.label = label

    def get_image(self):
        """ Returns the image as a numpy array. """
        image = np.frombuffer(self.image, dtype=np.uint8)
        return image.reshape(*self.size, self.channels)
```

### Menyimpan Ke Disk
Output kita untuk percobaan ini adalah sebuah gambar gambar tunggal, yang saat ini berada di memori sebagai larik NumPy. Anda ingin menyimpannya terlebih dahulu ke dalam disk sebagai gambar .png, dan menamainya dengan menggunakan ID gambar yang unik image_id. Hal ini dapat dilakukan dengan menggunakan paket Pillow yang telah Anda instal sebelumnya:


```python
from PIL import Image
import csv

def store_single_disk(image, image_id, label):
    """ Stores a single image as a .png file on disk.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    Image.fromarray(image).save(disk_dir / f"{image_id}.png")

    with open(disk_dir / f"{image_id}.csv", "wt") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        writer.writerow([label])
```


Selain menyimpan gambar, dalam aplikasi nyata, kita juga peduli dengan meta data yang terpasang pada gambar, yang dalam dataset contoh kita adalah label gambar. Ketika kita menyimpan gambar ke disk, ada beberapa opsi untuk menyimpan meta data.

Salah satu solusi adalah dengan menyandikan label ke dalam nama gambar. Ini memiliki keuntungan tidak memerlukan file tambahan.

Namun, menyimpan label dalam file terpisah memungkinkan kita untuk bekerja dengan label saja tanpa harus memuat gambar-gambar. Di atas ialah tampilan bahwa kita telah menyimpan label dalam file .csv terpisah.

### Menyimpan Ke Disk

LMDB adalah sistem penyimpanan kunci-nilai di mana setiap entri disimpan sebagai larik byte. Kunci adalah pengidentifikasi unik untuk setiap gambar, dan nilai adalah gambar itu sendiri. Keduanya diharapkan berupa string, jadi umumnya menggunakan serialisasi untuk menyimpan dan mengambil kembali data.

Pickle dapat digunakan untuk serialisasi, memungkinkan penyimpanan gambar beserta metadatanya dalam basis data. Ini menghindari kerumitan dalam melampirkan kembali metadatanya ketika memuat dataset dari disk.

kita akan membuat kelas sederhana untuk gambar dan metadatanya.


```python
class CIFAR_Image:
    def __init__(self, image, label):
        # Dimensions of image for reconstruction - not really necessary
        # for this dataset, but some datasets may include images of
        # varying sizes
        self.channels = image.shape[2]
        self.size = image.shape[:2]

        self.image = image.tobytes()
        self.label = label

    def get_image(self):
        """ Returns the image as a numpy array. """
        image = np.frombuffer(self.image, dtype=np.uint8)
        return image.reshape(*self.size, self.channels)
```

Kedua, karena LMDB dipetakan dengan memori, database baru perlu mengetahui berapa banyak memori yang akan digunakan.Hal ini relatif mudah dalam kasus kita, tetapi dapat menjadi masalah besar dalam kasus lain, yang akan Anda lihat secara lebih mendalam di bagian selanjutnya.LMDB menyebut variabel ini sebagai map_size. lalu kita masukkan kode untuk menyimpan satu gambar ke lmdb.


```python
import lmdb
import pickle

def store_single_lmdb(image, image_id, label):
    """ Stores a single image to a LMDB.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    map_size = len(image.tobytes()) * 10

    # Create a new LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), map_size=map_size)

    # Start a new write transaction
    with env.begin(write=True) as txn:
        # All key-value pairs need to be strings
        value = CIFAR_Image(image, label)
        key = f"{image_id:08}"
        txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()
```

### Menyimpan Ke HDF5


```python
import h5py

def store_single_hdf5(image, image_id, label):
    """ Stores a single image to an HDF5 file.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "image", np.shape(image), h5py.h5t.STD_U8BE, data=image
    )
    meta_set = file.create_dataset(
        "meta", np.shape(label), h5py.h5t.STD_U8BE, data=label
    )
    file.close()
```

h5py.h5t.STD_U8BE menentukan jenis data yang akan disimpan dalam kumpulan data, yang dalam hal ini berupa bilangan bulat 8-bit tidak bertanda.

## Experiments for Storing a Single Image


```python
_store_single_funcs = dict(
    disk=store_single_disk, lmdb=store_single_lmdb, hdf5=store_single_hdf5
)
```

Mari kita coba menyimpan gambar pertama dari CIFAR dan label yang sesuai, dan menyimpannya dengan tiga cara yang berbeda Ingatlah bahwa kita tertarik pada runtime, yang ditampilkan di sini dalam hitungan detik, dan juga penggunaan memori:


```python
from timeit import timeit

store_single_funcs = {
    "disk": store_single_disk,
    "lmdb": store_single_lmdb,
    "hdf5": store_single_hdf5
}

store_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_store_single_funcs[method](image, 0, label)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    store_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```

    Method: disk, Time usage: 0.05014248299994506
    Method: lmdb, Time usage: 0.015033435000077588
    Method: hdf5, Time usage: 0.018295998999974472


Ada dua hal yang bisa diambil di sini:
- Semua metode ini sangat cepat
- Dari segi penggunaan disk, LMDB menggunakan lebih banyak.

Yang jelas, meskipun LMDB memiliki sedikit keunggulan dalam hal performa, kami belum meyakinkan siapa pun, mengapa tidak menyimpan gambar pada disk. Lagipula, ini adalah format yang dapat dibaca oleh manusia, dan Anda dapat membuka dan melihatnya dari peramban sistem file apa pun! Nah, saatnya untuk melihat lebih banyak gambar

# Menyimpan banyak Gambar
Menyimpan banyak gambar sebagai file .png semudah memanggil store_single_method() beberapa kali. Namun hal ini tidak berlaku untuk LMDB atau HDF5, karena Anda tidak ingin memiliki file database yang berbeda untuk setiap gambar. Sebaliknya, Anda ingin memasukkan semua gambar ke dalam satu atau beberapa file.

Anda perlu sedikit mengubah kode dan membuat tiga fungsi baru yang menerima banyak gambar, store_many_disk(), store_many_lmdb(), dan store_many_hdf5:


```python
def store_many_disk(images, labels):
    """ Stores an array of images to disk
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Save all the images one by one
    for i, image in enumerate(images):
        Image.fromarray(image).save(disk_dir / f"{i}.png")

    # Save all the labels to the csv file
    with open(disk_dir / f"{num_images}.csv", "w") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for label in labels:
            # This typically would be more than just one value per row
            writer.writerow([label])

def store_many_lmdb(images, labels):
    """ Stores an array of images to LMDB.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    map_size = num_images * images[0].nbytes * 10

    # Create a new LMDB DB for all the images
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), map_size=map_size)

    # Same as before — but let's write all the images in a single transaction
    with env.begin(write=True) as txn:
        for i in range(num_images):
            # All key-value pairs need to be Strings
            value = CIFAR_Image(images[i], labels[i])
            key = f"{i:08}"
            txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()

def store_many_hdf5(images, labels):
    """ Stores an array of images to HDF5.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "images", np.shape(images), h5py.h5t.STD_U8BE, data=images
    )
    meta_set = file.create_dataset(
        "meta", np.shape(labels), h5py.h5t.STD_U8BE, data=labels
    )
    file.close()
```

## Mempersiapkan dataset nya
Sebelum menjalankan eksperimen lagi, pertama-tama mari kita gandakan ukuran dataset kita sehingga kita dapat menguji hingga 100.000 gambar:


```python
cutoffs = [10, 100, 1000, 10000, 100000]

# Let's double our images so that we have 100,000
images = np.concatenate((images, images), axis=0)
labels = np.concatenate((labels, labels), axis=0)

# Make sure you actually have 100,000 images and labels
print(np.shape(images))
print(np.shape(labels))
```

    (100000, 32, 32, 3)
    (100000,)


## Experiments for Storing a Many Image

Seperti yang Anda lakukan saat membaca banyak gambar, Anda dapat membuat kamus yang menangani semua fungsi dengan store_many_ dan menjalankan eksperimen:


```python
_store_many_funcs = dict(
    disk=store_many_disk, lmdb=store_many_lmdb, hdf5=store_many_hdf5
)

from timeit import timeit

store_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_store_many_funcs[method](images_, labels_)",
            setup="images_=images[:cutoff]; labels_=labels[:cutoff]",
            number=1,
            globals=globals(),
        )
        store_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, Time usage: {t}")
```

    Method: disk, Time usage: 0.009952358999953503
    Method: lmdb, Time usage: 0.009566790999997465
    Method: hdf5, Time usage: 0.0024474129999134675
    Method: disk, Time usage: 0.04980431399997087
    Method: lmdb, Time usage: 0.014300776000027327
    Method: hdf5, Time usage: 0.0028330260000757335
    Method: disk, Time usage: 0.4333289960000002
    Method: lmdb, Time usage: 0.04094848399995499
    Method: hdf5, Time usage: 0.00559077899993099
    Method: disk, Time usage: 4.3027495860000045
    Method: lmdb, Time usage: 0.47575845299991215
    Method: hdf5, Time usage: 0.0677763280000363
    Method: disk, Time usage: 46.9562531119999
    Method: lmdb, Time usage: 4.318730990000063
    Method: hdf5, Time usage: 1.1110412379999843


Grafik pertama menunjukkan waktu penyimpanan normal yang tidak disesuaikan, menyoroti perbedaan drastis antara menyimpan ke file .png dan LMDB atau HDF5.

Grafik kedua menunjukkan log pengaturan waktu, menyoroti bahwa HDF5 dimulai lebih lambat daripada LMDB tetapi, dengan jumlah gambar yang lebih besar, sedikit lebih unggul.

Meskipun hasil yang tepat dapat bervariasi tergantung pada mesin Anda, inilah alasan mengapa LMDB dan HDF5 layak dipertimbangkan. Berikut adalah kode yang menghasilkan grafik di atas:


```python
import matplotlib.pyplot as plt

def plot_with_legend(
    x_range, y_data, legend_labels, x_label, y_label, title, log=False
):
    """ Displays a single plot with multiple datasets and matching legends.
        Parameters:
        --------------
        x_range         list of lists containing x data
        y_data          list of lists containing y values
        legend_labels   list of string legend labels
        x_label         x axis label
        y_label         y axis label
    """
    plt.style.use("seaborn-whitegrid")
    plt.figure(figsize=(10, 7))

    if len(y_data) != len(legend_labels):
        raise TypeError(
            "Error: number of data sets does not match number of labels."
        )

    all_plots = []
    for data, label in zip(y_data, legend_labels):
        if log:
            temp, = plt.loglog(x_range, data, label=label)
        else:
            temp, = plt.plot(x_range, data, label=label)
        all_plots.append(temp)

    plt.title(title)
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    plt.legend(handles=all_plots)
    plt.show()

# Getting the store timings data to display
disk_x = store_many_timings["disk"]
lmdb_x = store_many_timings["lmdb"]
hdf5_x = store_many_timings["hdf5"]

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Storage time",
    log=False,
)

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Log storage time",
    log=True,
)
```

    <ipython-input-17-99d89538a067>:15: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.
      plt.style.use("seaborn-whitegrid")



    
![png](output_39_1.png)
    


    <ipython-input-17-99d89538a067>:15: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.
      plt.style.use("seaborn-whitegrid")



    
![png](output_39_3.png)
    


# Membaca Satu Gambar
Pertama, mari kita pertimbangkan kasus untuk membaca satu gambar kembali ke dalam array untuk masing-masing dari ketiga metode tersebut.

## Membaca Dari Disk
Dari ketiga metode tersebut, LMDB membutuhkan kerja keras ketika membaca file gambar kembali dari memori, karena adanya langkah serialisasi. Mari kita telusuri fungsi-fungsi yang membaca satu gambar untuk masing-masing dari tiga format penyimpanan.

Pertama, baca satu gambar dan meta-nya dari file .png dan .csv:


```python
def read_single_disk(image_id):
    """ Stores a single image to disk.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    image = np.array(Image.open(disk_dir / f"{image_id}.png"))

    with open(disk_dir / f"{image_id}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        label = int(next(reader)[0])

    return image, label
```

## Membaca dari LMDB
Selanjutnya, baca gambar dan meta yang sama dari LMDB dengan membuka lingkungan dan memulai transaksi baca:


```python
def read_single_lmdb(image_id):
    """ Stores a single image to LMDB.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Encode the key the same way as we stored it
        data = txn.get(f"{image_id:08}".encode("ascii"))
        # Remember it's a CIFAR_Image object that is loaded
        cifar_image = pickle.loads(data)
        # Retrieve the relevant bits
        image = cifar_image.get_image()
        label = cifar_image.label
    env.close()

    return image, label
```

## Membaca dari HDF5
terlihat sangat mirip dengan proses penulisan. Berikut ini adalah kode untuk membuka dan membaca file HDF5 dan mengurai gambar dan meta yang sama:


```python
def read_single_hdf5(image_id):
    """ Stores a single image to HDF5.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "r+")

    image = np.array(file["/image"]).astype("uint8")
    label = int(np.array(file["/meta"]).astype("uint8"))

    return image, label
```


```python
_read_single_funcs = dict(
    disk=read_single_disk, lmdb=read_single_lmdb, hdf5=read_single_hdf5
)
```

## Experiment for Reading a Single Image
Anda mungkin menduga bahwa percobaan untuk membaca satu gambar akan memberikan hasil yang agak sepele, tetapi inilah kode percobaannya:


```python
from timeit import timeit

read_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_read_single_funcs[method](0)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    read_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```

    Method: disk, Time usage: 0.007273611000073288
    Method: lmdb, Time usage: 0.0004251739999290294
    Method: hdf5, Time usage: 0.002564570000004096


Sedikit lebih cepat untuk membaca file .png dan .csv secara langsung dari disk, tetapi ketiga metode ini bekerja dengan sangat cepat. Eksperimen yang akan kita lakukan selanjutnya jauh lebih menarik.

# Reading Many Images
Sekarang Anda dapat menyesuaikan kode untuk membaca banyak gambar sekaligus. Ini kemungkinan besar adalah tindakan yang paling sering Anda lakukan, jadi kinerja runtime sangat penting.

Menyesuaikan Kode untuk Banyak Gambar
Memperluas fungsi di atas, Anda dapat membuat fungsi dengan read_many_, yang dapat digunakan untuk eksperimen berikutnya. Seperti sebelumnya, akan menarik untuk membandingkan performa ketika membaca jumlah gambar yang berbeda, yang diulang pada kode di bawah ini sebagai referensi:


```python
def read_many_disk(num_images):
    """ Reads image from disk.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Loop over all IDs and read each image in one by one
    for image_id in range(num_images):
        images.append(np.array(Image.open(disk_dir / f"{image_id}.png")))

    with open(disk_dir / f"{num_images}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for row in reader:
            labels.append(int(row[0]))
    return images, labels

def read_many_lmdb(num_images):
    """ Reads image from LMDB.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Read all images in one single transaction, with one lock
        # We could split this up into multiple transactions if needed
        for image_id in range(num_images):
            data = txn.get(f"{image_id:08}".encode("ascii"))
            # Remember that it's a CIFAR_Image object
            # that is stored as the value
            cifar_image = pickle.loads(data)
            # Retrieve the relevant bits
            images.append(cifar_image.get_image())
            labels.append(cifar_image.label)
    env.close()
    return images, labels

def read_many_hdf5(num_images):
    """ Reads image from HDF5.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "r+")

    images = np.array(file["/images"]).astype("uint8")
    labels = np.array(file["/meta"]).astype("uint8")

    return images, labels

_read_many_funcs = dict(
    disk=read_many_disk, lmdb=read_many_lmdb, hdf5=read_many_hdf5
)
```

## Experiment for Reading Many Images


```python
from timeit import timeit

read_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_read_many_funcs[method](num_images)",
            setup="num_images=cutoff",
            number=1,
            globals=globals(),
        )
        read_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, No. images: {cutoff}, Time usage: {t}")
```

    Method: disk, No. images: 10, Time usage: 0.006227099000057024
    Method: lmdb, No. images: 10, Time usage: 0.000629907999950774
    Method: hdf5, No. images: 10, Time usage: 0.004861294000079397
    Method: disk, No. images: 100, Time usage: 0.05898501399997258
    Method: lmdb, No. images: 100, Time usage: 0.0024304940000092756
    Method: hdf5, No. images: 100, Time usage: 0.002384250000091015
    Method: disk, No. images: 1000, Time usage: 0.49969871399991916
    Method: lmdb, No. images: 1000, Time usage: 0.022183963000088625
    Method: hdf5, No. images: 1000, Time usage: 0.004600165000056222
    Method: disk, No. images: 10000, Time usage: 2.7660184490000574
    Method: lmdb, No. images: 10000, Time usage: 0.13181374099997356
    Method: hdf5, No. images: 10000, Time usage: 0.03208745100005217
    Method: disk, No. images: 100000, Time usage: 28.42964642900006
    Method: lmdb, No. images: 100000, Time usage: 1.2920982169999888
    Method: hdf5, No. images: 100000, Time usage: 0.5202060300000539



```python
import matplotlib.pyplot as plt

# Data yang akan digunakan untuk plot
cutoffs = [100, 1000, 10000, 100000]  # Misalnya
read_many_timings = {
    "disk": [0.1, 0.5, 2.0, 10.0],  # Contoh data waktu untuk metode "disk"
    "lmdb": [0.05, 0.2, 1.0, 5.0],   # Contoh data waktu untuk metode "lmdb"
    "hdf5": [0.08, 0.3, 1.5, 7.0]    # Contoh data waktu untuk metode "hdf5"
}

# Plotting
plt.figure(figsize=(10, 6))  # Mengatur ukuran plot

# Membuat plot garis untuk setiap metode
for method, timings in read_many_timings.items():
    plt.plot(cutoffs, timings, marker='o', label=method)

# Menambahkan judul dan label sumbu
plt.title('Read Many Timings for Different Methods')
plt.xlabel('Number of Images')
plt.ylabel('Time (seconds)')

# Menambahkan legenda
plt.legend()

# Menampilkan plot
plt.grid(True)  # Menambahkan grid
plt.tight_layout()  # Menyesuaikan layout agar rapi
plt.show()

```


    
![png](output_54_0.png)
    


Dalam praktiknya, waktu tulis sering kali tidak terlalu penting dibandingkan waktu baca. Bayangkan Anda sedang melatih jaringan saraf tiruan pada gambar, dan hanya setengah dari seluruh dataset gambar yang dapat dimasukkan ke dalam RAM sekaligus. Setiap epoch pelatihan jaringan membutuhkan seluruh dataset, dan model membutuhkan beberapa ratus epoch untuk menyatu. Pada dasarnya, Anda akan membaca setengah dari dataset ke dalam memori setiap epoch. Plot ini membantu dalam mengevaluasi secara menyeluruh kinerja relatif dari tiga jenis sumber data yang berbeda dalam hal waktu yang diperlukan untuk operasi penyimpanan dan pembacaan data, serta memungkinkan untuk memilih metode yang paling sesuai dengan kebutuhan aplikasi.


```python

```
